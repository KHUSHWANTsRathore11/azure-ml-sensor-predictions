# Versioning Strategy

All versioning strategies for environments, components, models, and data.

## Overview

**Three Independent Versions:**
1. **Environment Version** - Python packages, Docker image (registration only)
2. **Component Version** - Pipeline logic, jobs (triggers retraining)
3. **Model Version** - Auto-generated by Azure ML

**Data Versioning:**
- Delta Lake version (reproducibility)
- Cutoff date (data filtering)

---

## Environment Version

**Location:** `components/environments/sensor-forecasting-env.yaml`

**Purpose:** Environment registration/promotion only (NOT in training hash)

**When to Bump:**
- Python package changes
- Docker base image changes
- System dependencies change

**Effect:**
- Triggers environment registration (Stage 1)
- May trigger promotion (Stage 2)
- **Does NOT trigger retraining**

**Example:**
```yaml
# components/environments/sensor-forecasting-env.yaml
name: custom-training-env
version: "1.1.0"  # ← Bump this
dependencies:
  - python=3.9
  - tensorflow=2.13.0
  - scikit-learn=1.3.0  # ← New package added
```

---

## Pipeline Component Version

**Location:** `components/training-pipeline-component.yaml` AND `config/circuits.yaml`

**Purpose:** Training execution and model lineage (IN training hash)

**When to Bump:**
- Pipeline logic changes
- New jobs added/removed
- Component inputs/outputs change

**Effect:**
- Triggers component registration (Stage 3)
- **Triggers retraining** (hash changes)
- Updates model lineage

**Example:**
```yaml
# components/training-pipeline-component.yaml
name: training-pipeline-component
version: "1.1.0"  # ← Bump this

# config/circuits.yaml
circuits:
  - pipeline_component_version: "1.1.0"  # ← Update this
```

---

## Training Hash

**Purpose:** Detect when retraining is needed

**Components:**
```python
hash_components = {
    'cutoff_date': '2025-11-01',
    'delta_version': 1,
    'pipeline_component_version': '1.0.0',  # ← Component version
    'training_days': 365,
    'hyperparameters': {'lstm_units': 64, ...}
}
training_hash = md5(json.dumps(hash_components, sort_keys=True))[:12]
```

**What Triggers Retraining:**
- ✅ `pipeline_component_version` changes
- ✅ `cutoff_date` changes
- ✅ `delta_version` changes
- ✅ `training_days` changes
- ✅ `hyperparameters` change
- ❌ `environment_version` changes (NOT in hash)

---

## Model Versioning

**Auto-Generated:** Azure ML assigns version automatically

**Tagging:**
```yaml
tags:
  training_hash: "a1b2c3d4e5f6"  # Links to training config
  plant_id: "PLANT001"
  circuit_id: "CIRCUIT01"
  cutoff_date: "2025-11-01"
  delta_version: "1"
  pipeline_component_version: "1.0.0"
```

**Lineage:** Training hash ensures reproducibility

---

## Delta Version Tracking

**Purpose:** Reproducible data snapshots

**Location:** `config/circuits.yaml`

```yaml
circuits:
  - delta_version: 1  # ← Increment manually when data schema changes
```

**When to Increment:**
- Data schema changes
- Feature engineering changes
- Data quality fixes

**MLTable Reference:**
```yaml
# data/mltables/PLANT001/CIRCUIT01/MLTable
paths:
  - pattern: abfss://container@storage.dfs.core.windows.net/delta/PLANT001/CIRCUIT01
type: mltable
transformations:
  - read_delta_lake:
      version_as_of: 1  # ← Uses delta_version from circuit config
```

---

## Cutoff Date vs Version vs Tag

**Cutoff Date:**
- Filters training data
- Changes trigger retraining
- Example: `2025-11-01`

**Delta Version:**
- Data snapshot version
- Changes trigger retraining
- Example: `1`, `2`, `3`

**Model Version:**
- Auto-generated by Azure ML
- Sequential: `1`, `2`, `3`, ...
- Cannot be manually set

**Model Tag:**
- Custom metadata
- Does NOT trigger retraining
- Example: `experiment: baseline`

---

## Version Update Workflows

### Update Environment Only

```bash
# 1. Update components/environments/sensor-forecasting-env.yaml
version: "1.0.0" → "1.1.0"

# 2. Run pipeline
# - Stage 1: Registers new environment
# - Stage 2: Promotes to registry
# - Stage 5-7: No retraining (hash unchanged)
```

### Update Component Only

```bash
# 1. Update components/training-pipeline-component.yaml
version: "1.0.0" → "1.1.0"

# 2. Update config/circuits.yaml
pipeline_component_version: "1.0.0" → "1.1.0"

# 3. Run pipeline
# - Stage 1-2: Skips (environment unchanged)
# - Stage 3: Registers new component
# - Stage 5-7: Triggers retraining (hash changed)
```

### Update Both

```bash
# 1. Update environment.yaml: version "1.0.0" → "2.0.0"
# 2. Update component.yaml: version "1.0.0" → "2.0.0"
# 3. Update circuits.yaml: pipeline_component_version "1.0.0" → "2.0.0"
# 4. Run pipeline: All stages run with new versions
```

### Update Data Version

```bash
# 1. Update config/circuits.yaml
delta_version: 1 → 2

# 2. Run pipeline
# - Triggers retraining (hash changed)
# - MLTable uses new Delta version
```

---

## Semantic Versioning

**Format:** `major.minor.patch`

**Environment:**
- Major: Python version, major package upgrades
- Minor: New packages, minor upgrades
- Patch: Bug fixes, patch updates

**Component:**
- Major: Breaking changes (schema, outputs)
- Minor: New features (new jobs, new logic)
- Patch: Bug fixes (same functionality)

---

## Best Practices

1. **Separate concerns** - Environment vs Component versioning
2. **Bump component** when logic changes
3. **Bump environment** when packages change
4. **Increment delta version** when data schema changes
5. **Use training hash** for model lineage
6. **Tag models** with all version info
7. **Document changes** in commit messages
